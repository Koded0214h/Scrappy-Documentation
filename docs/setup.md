# âš™ï¸ Scrapy Project Setup Guide

This guide helps you quickly set up and run the Scrapy web scraping framework locally.

---

## ğŸ“¦ Prerequisites

Make sure you have:

- Python 3.7 or higher
- `pip` (Python package manager)
- A terminal or command line interface
- (Optional but recommended) `virtualenv`

---

## ğŸ§ª 1. Create and Activate Virtual Environment

```bash
python -m venv env
source env/bin/activate       # For macOS/Linux
env\Scripts\activate          # For Windows
```


## ğŸ“¥ 2. Install Scrapy
```bash
python -m venv env
source env/bin/activate       # For macOS/Linux
env\Scripts\activate          # For Windows
```

## ğŸš€ 3. Create a New Scrapy Project
```bash
scrapy startproject scrappy_docs
cd scrappy_docs
```
This creates
```bash
scrappy_docs/
â”œâ”€â”€ scrapy.cfg
â””â”€â”€ scrappy_docs/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ items.py
    â”œâ”€â”€ middlewares.py
    â”œâ”€â”€ pipelines.py
    â”œâ”€â”€ settings.py
    â””â”€â”€ spiders/
```

## ğŸ•·ï¸ 4. Generate a Spider
```bash
cd scrappy_docs/spiders
scrapy genspider quotes quotes.toscrape.com
```

## â–¶ï¸ 5. Run the Spider
```bash
cd ../..
scrapy crawl quotes
```
To save output as a JSON file
```bash
scrapy crawl quotes -o output/quotes.json
```
Create the output/ folder first if it doesn't exist:
```bash
mkdir output
```

## ğŸ“„ 6. Project Folder Structure (After Setup)
```bash
scrappy_docs/
â”œâ”€â”€ scrapy.cfg
â”œâ”€â”€ SETUP.md
â”œâ”€â”€ output/
â”‚   â””â”€â”€ quotes.json
â””â”€â”€ scrappy_docs/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ items.py
    â”œâ”€â”€ middlewares.py
    â”œâ”€â”€ pipelines.py
    â”œâ”€â”€ settings.py
    â””â”€â”€ spiders/
        â””â”€â”€ quotes.py
```



## âœ… You're Ready!
Now you can:

ğŸ•·ï¸ Build more spiders

ğŸ› ï¸ Write custom logic for scraping anything

ğŸ“¤ Export to CSV, JSON, or databases

ğŸ“„ Document each spider in docs/spiders/*.

PS: _Ill add more details and code on each step as needed._